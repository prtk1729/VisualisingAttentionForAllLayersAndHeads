# VisualisingAttentionForAllLayersAndHeads
Coding a Transformer from Scratch and visualising attention maps for each layer and head

